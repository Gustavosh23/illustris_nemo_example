{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e00c2e",
   "metadata": {},
   "source": [
    "# About\n",
    "This code is used to download information of a subhalo from IllustrisTNG and adapt the hdf5 file to the GADGET-4 snapshot format that can be read by the GLnemo2 program.\n",
    "\n",
    "TNG project data acess:\n",
    "https://www.tng-project.org/data/\n",
    "\n",
    "TNG project data specifications:\n",
    "https://www.tng-project.org/data/docs/specifications/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a96613",
   "metadata": {},
   "source": [
    "# 1º downloading the necessary information from Illustris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a268ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs\n",
    "import requests\n",
    "\n",
    "#Halo parameters\n",
    "simulation_name = \"TNG50-1\"\n",
    "halo_id = 117255\n",
    "snapshot = 99\n",
    "\n",
    "#Base URL\n",
    "base_url = f\"http://www.tng-project.org/api/{simulation_name}\"\n",
    "\n",
    "#token API\n",
    "headers = {\"api-key\":\"[your_api_key]\"}  # replace \"your_api_key\" with the API key obtained when registering on the project site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19e392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a request for subhalo information\n",
    "url = f\"{base_url}/snapshots/{snapshot}/subhalos/{halo_id}\"\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    print(f\"Request failed with status {response.status_code}\")\n",
    "else:\n",
    "    subhalo_data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fb8432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download the halo file_117255_cutout.hdf5 completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Request to download the cut of the subhalo\n",
    "cutout_request = {\"gas\":\"Coordinates,Density,ElectronAbundance,InternalEnergy,Masses,GFM_Metallicity,ParticleIDs,Velocities\",\"dm\":\"Coordinates,ParticleIDs,Velocities\",\"stars\":\"Coordinates,Masses,GFM_Metallicity,ParticleIDs,GFM_StellarFormationTime,Velocities\"}  # modify as necessary\n",
    "url = f\"{base_url}/snapshots/{snapshot}/subhalos/{halo_id}/cutout.hdf5\"\n",
    "response = requests.get(url, headers=headers, params=cutout_request)\n",
    "\n",
    "#Final check if the order was successful\n",
    "if response.status_code != 200:\n",
    "    print(f\"Request failed with status {response.status_code}\")\n",
    "else:\n",
    "    with open(f\"halo_{halo_id}_cutout.hdf5\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Download the halo file_{halo_id}_cutout.hdf5 completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba91be",
   "metadata": {},
   "source": [
    "# 2º Creating a snapshot with the downloaded information that can be read by GLnemo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff87e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correction of the file_117255_cutout.hdf5 completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#libs\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Opens the 'si' and 'sh' files in read-only mode. The 'sh' is only used to get the format of the header information.\n",
    "with h5py.File(f'halo_{halo_id}_cutout.hdf5', 'r') as si, h5py.File('snapshot_header.hdf5', 'r') as sh:\n",
    "    \n",
    "    # Creates a copy of the 'sh' file called 'sh_copy.hdf5'\n",
    "    with h5py.File(f'halo_{halo_id}_correction.hdf5', 'w') as sh_copy:\n",
    "        \n",
    "        # Copy group by group from file 'sh' to 'sh_copy'\n",
    "        for item in sh:\n",
    "            sh.copy(item, sh_copy)\n",
    "        \n",
    "        # Inicializa um array para armazenar o número de partículas de cada tipo\n",
    "        numpart_file = np.zeros(6, dtype=np.uint64)\n",
    "        \n",
    "        # Initializes an array to store the number of particles of each type\n",
    "        for part_type in ['PartType0', 'PartType1', 'PartType2', 'PartType3', 'PartType4']:\n",
    "            if part_type in si:\n",
    "                # Copies the data from the 'si' file to 'sh_copy\n",
    "                if part_type in sh_copy:\n",
    "                    del sh_copy[part_type]  # Apaga o grupo existente\n",
    "                si.copy(part_type, sh_copy)\n",
    "                # Updates the number of particles for this type\n",
    "                numpart_file[int(part_type[-1])] = len(si[part_type]['Coordinates'])\n",
    "            else:\n",
    "                # If the particle type does not exist in 'si', delete it from 'sh_copy' and set the number of particles to 0\n",
    "                if part_type in sh_copy:\n",
    "                    del sh_copy[part_type]\n",
    "                numpart_file[int(part_type[-1])] = 0\n",
    "        \n",
    "        # Updates the header in 'sh_copy' with the correct number of particles\n",
    "        sh_copy['Header'].attrs['NumPart_ThisFile'] = numpart_file\n",
    "        sh_copy['Header'].attrs['NumPart_Total'] = numpart_file\n",
    "        sh_copy['Header'].attrs['NumPart_Total_HighWord'] = numpart_file\n",
    "\n",
    "        # Reads other attributes from the header of the 'si' file and updates them in the header of the 'sh_copy' file as necessary\n",
    "        time_value = si['Header'].attrs['Time']\n",
    "        sh_copy['Header'].attrs['Time'] = time_value\n",
    "        \n",
    "        redshift_value = si['Header'].attrs['Redshift']\n",
    "        sh_copy['Header'].attrs['Redshift'] = redshift_value\n",
    "        \n",
    "        masstable_value = si['Header'].attrs['MassTable']\n",
    "        sh_copy['Header'].attrs['MassTable'] =  masstable_value\n",
    "        \n",
    "        boxsize_value = si['Header'].attrs['BoxSize']\n",
    "        sh_copy['Header'].attrs['BoxSize'] =  boxsize_value\n",
    "        \n",
    "        \n",
    "        print(f\"Correction of the file_{halo_id}_cutout.hdf5 completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
